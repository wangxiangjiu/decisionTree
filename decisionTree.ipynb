{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import csv\n",
    "from numpy import corrcoef, sum, log, arange\n",
    "from numpy.random import rand\n",
    "from pylab import pcolor, show, colorbar, xticks, yticks\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "def spam_DT_predict():\n",
    "    train_size = 5000\n",
    "    vali_size = 4740 \n",
    "    spam_data = sio.loadmat('dist/spam_data.mat')\n",
    "    spam_train_label = spam_data['training_labels'][0]\n",
    "    spam_train_data = spam_data['training_data']\n",
    "    spam_test_data = spam_data['test_data']\n",
    "    reshaped_train_labels = spam_train_label.reshape((spam_train_label.shape[0],1))\n",
    "\n",
    "    concat_train_w_labels = np.concatenate((spam_train_data, reshaped_train_labels), axis = 1)\n",
    "    \n",
    "    file = open('dist/test.csv', 'w+')\n",
    "    file.write('Id,Category\\n')\n",
    "    predict = LDA(spam_test_data, concat_train_w_labels, 2)\n",
    "    for i in range(len(predict)):\n",
    "        file.write('%s' % i + ',' + '%s' % predict[i] +'\\n')\n",
    "    file.close()\n",
    "\n",
    "def spam():\n",
    "    return 0\n",
    "\n",
    "# numcols are the columns that have numbers.\n",
    "def clean(fileName, numcols, saveFile):\n",
    "    df = pd.read_csv('hw5_census_dist/train_data.csv')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data = []\n",
    "    #getting all the column headers. all features. \n",
    "    titles = list(df)\n",
    "    \n",
    "    # array of all the column headers that have numbers.\n",
    "    num = []\n",
    "    for i in num_cols: \n",
    "        num.append(titles[i])\n",
    "    \n",
    "    for i in titles:\n",
    "        if i in num:\n",
    "            list_column = [float(j) if j != \"?\" else np.nan for j in df[i]]\n",
    "            data.append(list_column)\n",
    "        else:\n",
    "            le.fit(df[i])\n",
    "            list_column = [le.transform([k])[0] if k != \"?\" else np.nan for k in df[i]]\n",
    "            data.append(list_column)\n",
    "\n",
    "    #Imputer used to replace all NaN data with the mean. \n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp.fit(data)\n",
    "    nanChangeData = imp.transform(data)\n",
    "    new_data = np.transpose(np.array(nanChangeData))\n",
    "    sio.savemat(saveFile, {'new_data':new_data})\n",
    "    return titles\n",
    "\n",
    "numcols = [0, 2, 4, 10, 11, 12, 14]\n",
    "numcols_test = [0, 2, 4, 10, 11, 12]\n",
    "features_train = clean('hw5_census_dist/train_data.csv', numcols, 'hw5_census_dist/train_census.mat')\n",
    "features_test = clean('hw5_census_dist/test_data.csv', numcols_test, 'hw5_census_dist/test_census.mat')\n",
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32724, 14) (32724,)\n",
      "(32724, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  5.90000000e+01,   4.00000000e+00,   3.07423000e+05,\n",
       "          6.00000000e+00,   5.00000000e+00,   4.00000000e+00,\n",
       "          8.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          5.00000000e+01,   3.90000000e+01]),\n",
       " 0,\n",
       " array([[  5.90000000e+01,   4.00000000e+00,   3.07423000e+05, ...,\n",
       "           5.00000000e+01,   3.90000000e+01,   0.00000000e+00],\n",
       "        [  3.20000000e+01,   4.00000000e+00,   1.92965000e+05, ...,\n",
       "           4.50000000e+01,   3.90000000e+01,   0.00000000e+00],\n",
       "        [  1.90000000e+01,   4.00000000e+00,   1.25591000e+05, ...,\n",
       "           4.00000000e+01,   3.90000000e+01,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  4.10000000e+01,   6.00000000e+00,   3.44624000e+05, ...,\n",
       "           6.00000000e+01,   3.90000000e+01,   1.00000000e+00],\n",
       "        [  4.70000000e+01,   6.00000000e+00,   1.04489000e+05, ...,\n",
       "           4.00000000e+01,   3.90000000e+01,   1.00000000e+00],\n",
       "        [  2.50000000e+01,   4.00000000e+00,   1.86925000e+05, ...,\n",
       "           4.80000000e+01,   3.90000000e+01,   0.00000000e+00]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def census():\n",
    "    # getting training data\n",
    "    train_data = sio.loadmat('hw5_census_dist/train_census.mat')\n",
    "    train_data = train_data['new_data']\n",
    "    train_data = np.array(train_data)\n",
    "    training_data, training_labels = train_data[:, :-1], train_data[:, -1].astype(int)\n",
    "    print(training_data.shape, training_labels.shape)\n",
    "    \n",
    "    # getting test data\n",
    "    test_data = sio.loadmat('hw5_census_dist/test_census.mat')\n",
    "    test_data = test_data['new_data']\n",
    "    test_data = np.array(test_data)\n",
    "    print(test_data.shape)\n",
    "    return training_data[0], training_labels[0], test_data\n",
    "    \n",
    "def titanic():\n",
    "    # Do something\n",
    "    return 0\n",
    "    \n",
    "class Node:\n",
    "    split_rule = None\n",
    "    left = None\n",
    "    right = None\n",
    "    label = None\n",
    "\n",
    "    def __init__(self, split_rule, left, right, label):\n",
    "        self.split_rule = split_rule\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.label = label\n",
    "        \n",
    "class leaf:\n",
    "    label = None\n",
    "    \n",
    "    def __init__(self,label):\n",
    "        this.label = label\n",
    "        \n",
    "#process_census()\n",
    "census()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    root = None\n",
    "    def __init__(self, params):\n",
    "        # Do something\n",
    "        return 0\n",
    "    \n",
    "    def impurity(left_label_hist, right_label_hist):\n",
    "        size_left = 0\n",
    "        size_right = 0\n",
    "        H_left = 0\n",
    "        H_right = 0\n",
    "        \n",
    "        # for each class in the left_label_hist, add together the total size of the left. \n",
    "        for c in left_label_hist:\n",
    "            size_left = size_left + len(left_label_hist[c])\n",
    "        \n",
    "        for c in right_label_hist:\n",
    "            size_right = size_right + len(right_label_hist[c])\n",
    "        \n",
    "        for c in left_label_hist:\n",
    "            p_c = len(left_label_hist[c])/float(size_left)\n",
    "            H_left = H_left - p_c*np.log(p_c)\n",
    "            \n",
    "        for c in right_label_hist:\n",
    "            p_c = len(right_label_hist[c])/float(size_right)\n",
    "            H_right = H_right - p_c*np.log(p_c)\n",
    "        \n",
    "        return (H_left * size_left + H_right * size_right) / float(size_left + size_right)\n",
    "        \n",
    "    def segmenter(data, labels):\n",
    "        # Do something\n",
    "        data \n",
    "        return 0\n",
    "    \n",
    "    def train(data, labels):\n",
    "        return 0\n",
    "          \n",
    "    def predict(data):\n",
    "        # Do something\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTree(params)\n",
    "classifier.train(train_data, train_labels)\n",
    "predictions = classifier.predit(test_data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
